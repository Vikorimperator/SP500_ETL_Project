{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar variables del archivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexión a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de conexión desde .env\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "# Crear la URL de la base de datos\n",
    "DATABASE_URL = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "# Crear el engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Crear una conexión cruda (raw connection)\n",
    "connection = engine.raw_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82056/2915492561.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date   open   high    low  close    volume   name\n",
      "0       2013-02-08  66.14  66.83  65.97  66.60    659052    XEC\n",
      "1       2013-02-08  14.65  14.83  14.61  14.66   7731572     WU\n",
      "2       2013-02-08  34.69  34.92  34.68  34.88  18425772    WFC\n",
      "3       2013-02-08  75.02  75.99  74.96  75.85    911179    ZBH\n",
      "4       2013-02-08  27.01  27.64  27.01  27.09   1206284    XYL\n",
      "...            ...    ...    ...    ...    ...       ...    ...\n",
      "619529  2018-08-02  50.00  50.00  50.00  50.00        50   APTV\n",
      "619530  2018-08-02  50.00  50.00  50.00  50.00        50    AGN\n",
      "619531  2018-08-02  50.00  50.00  50.00  50.00        50  DISCA\n",
      "619532  2018-08-02  50.00  50.00  50.00  50.00        50    DPS\n",
      "619533  2018-08-02  50.00  50.00  50.00  50.00        50    DXC\n",
      "\n",
      "[619534 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Consulta SQL para unir los datos de `stock_prices` con los nombres de `companies`\n",
    "    query = \"\"\"\n",
    "    SELECT sp.date, sp.open, sp.high, sp.low, sp.close, sp.volume, c.name AS Name\n",
    "    FROM stock_prices sp\n",
    "    JOIN companies c ON sp.company_id = c.id\n",
    "    ORDER BY sp.date;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "    df = pd.read_sql(query, connection)\n",
    "\n",
    "finally:\n",
    "    # Cerrar la conexión cruda\n",
    "    connection.close()\n",
    "\n",
    "# Mostrar los primeros 5 registros\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta la fecha maxima antes de la insercion del dato nuevo: 2018-08-02\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos la fecha maxima\n",
    "print(f'Esta la fecha maxima antes de la insercion del dato nuevo: {df.date.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Identificar duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"Filas duplicadas: {duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrar y volver a crear las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas eliminadas y recreadas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82056/1266835711.py:3: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  connection.execute(\"DROP TABLE IF EXISTS stock_prices;\")\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    # Eliminar las tablas (DROP)\n",
    "    connection.execute(\"DROP TABLE IF EXISTS stock_prices;\")\n",
    "    connection.execute(\"DROP TABLE IF EXISTS companies;\")\n",
    "\n",
    "    # Crear las tablas nuevamente\n",
    "    connection.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS companies (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        name VARCHAR(10) NOT NULL UNIQUE\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    connection.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stock_prices (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        company_id INTEGER REFERENCES companies(id),\n",
    "        date DATE NOT NULL,\n",
    "        open NUMERIC(10, 2),\n",
    "        high NUMERIC(10, 2),\n",
    "        low NUMERIC(10, 2),\n",
    "        close NUMERIC(10, 2),\n",
    "        volume BIGINT\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "print(\"Tablas eliminadas y recreadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA='../'+os.getenv('DAILY_STOCK_DATA')\n",
    "\n",
    "def load_csv_to_dataframe():\n",
    "    # Lista para almacenar los DataFrames\n",
    "    dataframes = []\n",
    "    \n",
    "    # Iterar sobre los archivos en la carpeta\n",
    "    for filename in os.listdir(DAILY_DATA):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(DAILY_DATA, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Convertir nombres de columnas a minúsculas\n",
    "            df.columns = df.columns.str.lower()\n",
    "            \n",
    "            # Convertir la columna 'date' a tipo datetime (si existe)\n",
    "            if 'date' in df.columns:\n",
    "                df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            dataframes.append(df)\n",
    "    \n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    if dataframes:\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Retorna un DataFrame vacío si no hay archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>TPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>SYMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>FLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>RHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>MMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>VNO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>RSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PEP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  open  high  low  close  volume  name\n",
       "0   2018-08-02    50    50   50     50      50   TPR\n",
       "1   2018-08-02    50    50   50     50      50  SYMC\n",
       "2   2018-08-02    50    50   50     50      50   FLR\n",
       "3   2018-08-02    50    50   50     50      50   RHI\n",
       "4   2018-08-02    50    50   50     50      50   MMC\n",
       "..         ...   ...   ...  ...    ...     ...   ...\n",
       "500 2018-08-02    50    50   50     50      50   VNO\n",
       "501 2018-08-02    50    50   50     50      50   RSG\n",
       "502 2018-08-02    50    50   50     50      50   AAL\n",
       "503 2018-08-02    50    50   50     50      50  MSFT\n",
       "504 2018-08-02    50    50   50     50      50   PEP\n",
       "\n",
       "[505 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamar la funcion para cargar los datos diarios de stock\n",
    "latest_stock_df = load_csv_to_dataframe()\n",
    "latest_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_dates():\n",
    "    # Consulta SQL\n",
    "    query = \"\"\"\n",
    "    SELECT c.name, MAX(sp.date) as latest_date\n",
    "    FROM stock_prices sp\n",
    "    JOIN companies c ON sp.company_id = c.id\n",
    "    GROUP BY c.name;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ejecutar la consulta usando SQLAlchemy\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(query))\n",
    "        \n",
    "        # Convertir los resultados a un diccionario {company_name: latest_date}\n",
    "        latest_dates_dict = {row['name']: row['latest_date'] for row in result}\n",
    "\n",
    "    return latest_dates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamar a la función para obtener los datos\n",
    "latest_dates_dict = get_latest_dates()\n",
    "latest_dates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_new_data(latest_stock_df, latest_dates_dict):\n",
    "    \"\"\"\n",
    "    Filtra las filas de latest_stock_df que tienen fechas más recientes que las ya registradas en la base de datos.\n",
    "    \"\"\"\n",
    "    # Filtrar el DataFrame para obtener solo los datos más recientes\n",
    "    filtered_df = latest_stock_df[latest_stock_df.apply(\n",
    "        lambda row: pd.Timestamp(row['date']) > pd.Timestamp(latest_dates_dict.get(row['name'], '1900-01-01')), axis=1)]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>TPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>SYMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>FLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>RHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>MMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>VNO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>RSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PEP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  open  high  low  close  volume  name\n",
       "0   2018-08-02    50    50   50     50      50   TPR\n",
       "1   2018-08-02    50    50   50     50      50  SYMC\n",
       "2   2018-08-02    50    50   50     50      50   FLR\n",
       "3   2018-08-02    50    50   50     50      50   RHI\n",
       "4   2018-08-02    50    50   50     50      50   MMC\n",
       "..         ...   ...   ...  ...    ...     ...   ...\n",
       "500 2018-08-02    50    50   50     50      50   VNO\n",
       "501 2018-08-02    50    50   50     50      50   RSG\n",
       "502 2018-08-02    50    50   50     50      50   AAL\n",
       "503 2018-08-02    50    50   50     50      50  MSFT\n",
       "504 2018-08-02    50    50   50     50      50   PEP\n",
       "\n",
       "[505 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stock_data = filter_new_data(latest_stock_df, latest_dates_dict)\n",
    "new_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_to_db(new_stock_data):\n",
    "    \"\"\"\n",
    "    Inserta los datos nuevos en las tablas `companies` y `stock_prices`.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        # Paso 1: Insertar compañías nuevas en la tabla `companies`\n",
    "        for company in new_stock_data['name'].unique():\n",
    "            query = text(\"\"\"\n",
    "            INSERT INTO companies (name)\n",
    "            VALUES (:company)\n",
    "            ON CONFLICT (name) DO NOTHING\n",
    "            \"\"\")\n",
    "            connection.execute(query, {\"company\": company})\n",
    "        \n",
    "        # Paso 2: Insertar los precios en la tabla `stock_prices`\n",
    "        for _, row in new_stock_data.iterrows():\n",
    "            # Obtener el company_id de la tabla `companies`\n",
    "            query = text(\"\"\"\n",
    "            SELECT id FROM companies WHERE name = :company_name\n",
    "            \"\"\")\n",
    "            company_id = connection.execute(query, {\"company_name\": row['name']}).scalar()\n",
    "            \n",
    "            # Insertar en `stock_prices`\n",
    "            query = text(\"\"\"\n",
    "            INSERT INTO stock_prices (company_id, date, open, high, low, close, volume)\n",
    "            VALUES (:company_id, :date, :open, :high, :low, :close, :volume)\n",
    "            \"\"\")\n",
    "            connection.execute(query, {\n",
    "                \"company_id\": company_id,\n",
    "                \"date\": row['date'],\n",
    "                \"open\": row['open'],\n",
    "                \"high\": row['high'],\n",
    "                \"low\": row['low'],\n",
    "                \"close\": row['close'],\n",
    "                \"volume\": row['volume']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la función para insertar los datos nuevos\n",
    "insert_data_to_db(new_stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82056/360956488.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_updated = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Connection' object has no attribute 'cursor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    SELECT sp.date, sp.open, sp.high, sp.low, sp.close, sp.volume, c.name AS Name\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    FROM stock_prices sp\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    JOIN companies c ON sp.company_id = c.id\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    ORDER BY sp.date;\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Ejecutar la consulta y cargar los resultados en un DataFrame\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     df_updated \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Cerrar la conexión cruda\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     connection\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/home/viktor/kiosko_challange/kiosko/lib/python3.10/site-packages/pandas/io/sql.py:706\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m/home/viktor/kiosko_challange/kiosko/lib/python3.10/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/viktor/kiosko_challange/kiosko/lib/python3.10/site-packages/pandas/io/sql.py:2672\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery must be a string unless using sqlalchemy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2671\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m-> 2672\u001b[0m cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m()\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Connection' object has no attribute 'cursor'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Consulta SQL para unir los datos de `stock_prices` con los nombres de `companies`\n",
    "    query = \"\"\"\n",
    "    SELECT sp.date, sp.open, sp.high, sp.low, sp.close, sp.volume, c.name AS Name\n",
    "    FROM stock_prices sp\n",
    "    JOIN companies c ON sp.company_id = c.id\n",
    "    ORDER BY sp.date;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "    df_updated = pd.read_sql(query, connection)\n",
    "\n",
    "finally:\n",
    "    # Cerrar la conexión cruda\n",
    "    connection.close()\n",
    "\n",
    "# Mostrar los primeros 5 registros\n",
    "print(df_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta la fecha maxima antes de la insercion del dato nuevo: 2018-08-02\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos la fecha maxima\n",
    "print(f'Esta la fecha maxima antes de la insercion del dato nuevo: {df_updated.date.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Identificar duplicados\n",
    "duplicados = df_updated.duplicated().sum()\n",
    "print(f\"Filas duplicadas: {duplicados}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kiosko",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
